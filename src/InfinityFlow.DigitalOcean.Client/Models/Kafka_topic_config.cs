// <auto-generated/>
#pragma warning disable CS0618
using Microsoft.Kiota.Abstractions.Extensions;
using Microsoft.Kiota.Abstractions.Serialization;
using System.Collections.Generic;
using System.IO;
using System;
namespace InfinityFlow.DigitalOcean.Client.Models
{
    [global::System.CodeDom.Compiler.GeneratedCode("Kiota", "1.0.0")]
    #pragma warning disable CS1591
    public partial class Kafka_topic_config : IAdditionalDataHolder, IParsable
    #pragma warning restore CS1591
    {
        /// <summary>Stores additional data not described in the OpenAPI description found when deserializing. Can be used for serialization as well.</summary>
        public IDictionary<string, object> AdditionalData { get; set; }
        /// <summary>The cleanup_policy sets the retention policy to use on log segments. &apos;delete&apos; will discard old segments when retention time/size limits are reached. &apos;compact&apos; will enable log compaction, resulting in retention of the latest value for each key.</summary>
        public global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_cleanup_policy? CleanupPolicy { get; set; }
        /// <summary>The compression_type specifies the compression type of the topic.</summary>
        public global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_compression_type? CompressionType { get; set; }
        /// <summary>The delete_retention_ms specifies how long (in ms) to retain delete tombstone markers for topics.</summary>
        public int? DeleteRetentionMs { get; set; }
        /// <summary>The file_delete_delay_ms specifies the time (in ms) to wait before deleting a file from the filesystem.</summary>
        public int? FileDeleteDelayMs { get; set; }
        /// <summary>The flush_messages specifies the number of messages to accumulate on a log partition before messages are flushed to disk.</summary>
        public int? FlushMessages { get; set; }
        /// <summary>The flush_ms specifies the maximum time (in ms) that a message is kept in memory before being flushed to disk.</summary>
        public int? FlushMs { get; set; }
        /// <summary>The index_interval_bytes specifies the number of bytes between entries being added into te offset index.</summary>
        public int? IndexIntervalBytes { get; set; }
        /// <summary>The max_compaction_lag_ms specifies the maximum amount of time (in ms) that a message will remain uncompacted. This is only applicable if the logs are have compaction enabled.</summary>
        public int? MaxCompactionLagMs { get; set; }
        /// <summary>The max_messages_bytes specifies the largest record batch size (in bytes) that can be sent to the server.  This is calculated after compression if compression is enabled.</summary>
        public int? MaxMessageBytes { get; set; }
        /// <summary>The message_down_conversion_enable specifies whether down-conversion of message formats is enabled to satisfy consumer requests. When &apos;false&apos;, the broker will not perform conversion for consumers expecting older message formats. The broker will respond with an `UNSUPPORTED_VERSION` error for consume requests from these older clients.</summary>
        public bool? MessageDownConversionEnable { get; set; }
        /// <summary>The message_format_version specifies the message format version used by the broker to append messages to the logs. The value of this setting is assumed to be 3.0-IV1 if the broker protocol version is 3.0 or higher. By setting a  particular message format version, all existing messages on disk must be smaller or equal to the specified version.</summary>
        public global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_format_version? MessageFormatVersion { get; set; }
        /// <summary>The message_timestamp_type specifies whether to use the message create time or log append time as the timestamp on a message.</summary>
        public global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_timestamp_type? MessageTimestampType { get; set; }
        /// <summary>The min_cleanable_dirty_ratio specifies the frequency of log compaction (if enabled) in relation to duplicates present in the logs. For example, at 0.5, at most 50% of the log could be duplicates before compaction would begin.</summary>
        public float? MinCleanableDirtyRatio { get; set; }
        /// <summary>The min_compaction_lag_ms specifies the minimum time (in ms) that a message will remain uncompacted in the log. Only relevant if log compaction is enabled.</summary>
        public int? MinCompactionLagMs { get; set; }
        /// <summary>The min_insync_replicas specifies the number of replicas that must ACK a write for the write to be considered successful.</summary>
        public int? MinInsyncReplicas { get; set; }
        /// <summary>The preallocate specifies whether a file should be preallocated on disk when creating a new log segment.</summary>
        public bool? Preallocate { get; set; }
        /// <summary>The retention_bytes specifies the maximum size of the log (in bytes) before deleting messages. -1 indicates that there is no limit.</summary>
        public int? RetentionBytes { get; set; }
        /// <summary>The retention_ms specifies the maximum amount of time (in ms) to keep a message before deleting it.</summary>
        public int? RetentionMs { get; set; }
        /// <summary>The segment_bytes specifies the maximum size of a single log file (in bytes).</summary>
        public int? SegmentBytes { get; set; }
        /// <summary>The segment_jitter_ms specifies the maximum random jitter subtracted from the scheduled segment roll time to avoid thundering herds of segment rolling.</summary>
        public int? SegmentJitterMs { get; set; }
        /// <summary>The segment_ms specifies the period of time after which the log will be forced to roll if the segment file isn&apos;t full. This ensures that retention can delete or compact old data.</summary>
        public int? SegmentMs { get; set; }
        /// <summary>
        /// Instantiates a new <see cref="global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config"/> and sets the default values.
        /// </summary>
        public Kafka_topic_config()
        {
            AdditionalData = new Dictionary<string, object>();
            CleanupPolicy = global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_cleanup_policy.Delete;
            CompressionType = global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_compression_type.Producer;
            FlushMessages = 9223372;
            FlushMs = 9223372;
            MaxCompactionLagMs = 9223372;
            MessageFormatVersion = global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_format_version.ThreeZeroIV1;
            MessageTimestampType = global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_timestamp_type.Create_time;
        }
        /// <summary>
        /// Creates a new instance of the appropriate class based on discriminator value
        /// </summary>
        /// <returns>A <see cref="global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config"/></returns>
        /// <param name="parseNode">The parse node to use to read the discriminator value and create the object</param>
        public static global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config CreateFromDiscriminatorValue(IParseNode parseNode)
        {
            _ = parseNode ?? throw new ArgumentNullException(nameof(parseNode));
            return new global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config();
        }
        /// <summary>
        /// The deserialization information for the current model
        /// </summary>
        /// <returns>A IDictionary&lt;string, Action&lt;IParseNode&gt;&gt;</returns>
        public virtual IDictionary<string, Action<IParseNode>> GetFieldDeserializers()
        {
            return new Dictionary<string, Action<IParseNode>>
            {
                { "cleanup_policy", n => { CleanupPolicy = n.GetEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_cleanup_policy>(); } },
                { "compression_type", n => { CompressionType = n.GetEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_compression_type>(); } },
                { "delete_retention_ms", n => { DeleteRetentionMs = n.GetIntValue(); } },
                { "file_delete_delay_ms", n => { FileDeleteDelayMs = n.GetIntValue(); } },
                { "flush_messages", n => { FlushMessages = n.GetIntValue(); } },
                { "flush_ms", n => { FlushMs = n.GetIntValue(); } },
                { "index_interval_bytes", n => { IndexIntervalBytes = n.GetIntValue(); } },
                { "max_compaction_lag_ms", n => { MaxCompactionLagMs = n.GetIntValue(); } },
                { "max_message_bytes", n => { MaxMessageBytes = n.GetIntValue(); } },
                { "message_down_conversion_enable", n => { MessageDownConversionEnable = n.GetBoolValue(); } },
                { "message_format_version", n => { MessageFormatVersion = n.GetEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_format_version>(); } },
                { "message_timestamp_type", n => { MessageTimestampType = n.GetEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_timestamp_type>(); } },
                { "min_cleanable_dirty_ratio", n => { MinCleanableDirtyRatio = n.GetFloatValue(); } },
                { "min_compaction_lag_ms", n => { MinCompactionLagMs = n.GetIntValue(); } },
                { "min_insync_replicas", n => { MinInsyncReplicas = n.GetIntValue(); } },
                { "preallocate", n => { Preallocate = n.GetBoolValue(); } },
                { "retention_bytes", n => { RetentionBytes = n.GetIntValue(); } },
                { "retention_ms", n => { RetentionMs = n.GetIntValue(); } },
                { "segment_bytes", n => { SegmentBytes = n.GetIntValue(); } },
                { "segment_jitter_ms", n => { SegmentJitterMs = n.GetIntValue(); } },
                { "segment_ms", n => { SegmentMs = n.GetIntValue(); } },
            };
        }
        /// <summary>
        /// Serializes information the current object
        /// </summary>
        /// <param name="writer">Serialization writer to use to serialize this model</param>
        public virtual void Serialize(ISerializationWriter writer)
        {
            _ = writer ?? throw new ArgumentNullException(nameof(writer));
            writer.WriteEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_cleanup_policy>("cleanup_policy", CleanupPolicy);
            writer.WriteEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_compression_type>("compression_type", CompressionType);
            writer.WriteIntValue("delete_retention_ms", DeleteRetentionMs);
            writer.WriteIntValue("file_delete_delay_ms", FileDeleteDelayMs);
            writer.WriteIntValue("flush_messages", FlushMessages);
            writer.WriteIntValue("flush_ms", FlushMs);
            writer.WriteIntValue("index_interval_bytes", IndexIntervalBytes);
            writer.WriteIntValue("max_compaction_lag_ms", MaxCompactionLagMs);
            writer.WriteIntValue("max_message_bytes", MaxMessageBytes);
            writer.WriteBoolValue("message_down_conversion_enable", MessageDownConversionEnable);
            writer.WriteEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_format_version>("message_format_version", MessageFormatVersion);
            writer.WriteEnumValue<global::InfinityFlow.DigitalOcean.Client.Models.Kafka_topic_config_message_timestamp_type>("message_timestamp_type", MessageTimestampType);
            writer.WriteFloatValue("min_cleanable_dirty_ratio", MinCleanableDirtyRatio);
            writer.WriteIntValue("min_compaction_lag_ms", MinCompactionLagMs);
            writer.WriteIntValue("min_insync_replicas", MinInsyncReplicas);
            writer.WriteBoolValue("preallocate", Preallocate);
            writer.WriteIntValue("retention_bytes", RetentionBytes);
            writer.WriteIntValue("retention_ms", RetentionMs);
            writer.WriteIntValue("segment_bytes", SegmentBytes);
            writer.WriteIntValue("segment_jitter_ms", SegmentJitterMs);
            writer.WriteIntValue("segment_ms", SegmentMs);
            writer.WriteAdditionalData(AdditionalData);
        }
    }
}
#pragma warning restore CS0618
